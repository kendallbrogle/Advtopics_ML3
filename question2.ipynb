{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To copy this template: File -> Save a Copy in Drive\n",
        "\n",
        "***DISCLAIMER**: In case of any discrepancy in the assignment instruction, please refer to the `PDF` document.*"
      ],
      "metadata": {
        "id": "OMAdi9qgC-B9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2 - Neural Network Training and Backpropagation"
      ],
      "metadata": {
        "id": "NcDhlfqyBd6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1"
      ],
      "metadata": {
        "id": "-id00ye6CNLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "%matplotlib inline\n",
        "#Load data and create X and y variables\n",
        "data = loadmat('/content/sample_data/ex3data1.mat')\n",
        "X = data['X']\n",
        "y = data['y']\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G6kUY4qGwLb",
        "outputId": "d04ee803-0313-469e-bc17-5f39d2308e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
              " '__version__': '1.0',\n",
              " '__globals__': [],\n",
              " 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " 'y': array([[10],\n",
              "        [10],\n",
              "        [10],\n",
              "        ...,\n",
              "        [ 9],\n",
              "        [ 9],\n",
              "        [ 9]], dtype=uint8)}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['X']\n",
        "y = data['y']\n",
        "\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "N_gd8wvAG7Pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c59eba8-32cd-4469-e9a8-96cb49978f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 400), (5000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transorm y data - vector of length k where index n is \"hot\" (1) while the rest are zero\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_onehot = encoder.fit_transform(y)\n",
        "y_onehot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnseDYnHzdlW",
        "outputId": "ac237dd6-5f0b-4760-9b04-48dc74870de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# needs to be more sensitive - account for factor of 2\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-2*z))"
      ],
      "metadata": {
        "id": "vTNdohMM9x99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2"
      ],
      "metadata": {
        "id": "e1D_yfneCWqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaITPmRaf-BK"
      },
      "outputs": [],
      "source": [
        "# propogate with two hidden layers - additional a and z values\n",
        "def forward_propagate(X, theta1, theta2, theta3):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    # Input layer to Hidden Layer 1\n",
        "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
        "    z2 = a1 @ theta1.T\n",
        "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
        "\n",
        "    # Hidden Layer 1 to Hidden Layer 2\n",
        "    z3 = a2 @ theta2.T\n",
        "    a3 = np.insert(sigmoid(z3), 0, values=np.ones(m), axis=1)\n",
        "\n",
        "    # Hidden Layer 2 to Output Layer\n",
        "    z4 = a3 @ theta3.T\n",
        "    h = sigmoid(z4)\n",
        "\n",
        "    return a1, z2, a2, z3, a3, z4, h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3"
      ],
      "metadata": {
        "id": "_7R7c6Mv91wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_with_regularization(params, input_size, hidden_size1, hidden_size2, num_labels, X, y, learning_rate):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "\n",
        "    # reshape the parameter array into parameter matrices for each layer\n",
        "    theta1_start = 0\n",
        "    theta1_end = hidden_size1 * (input_size + 1)\n",
        "    theta2_end = theta1_end + (hidden_size1 + 1) * hidden_size2\n",
        "    theta1 = np.matrix(np.reshape(params[theta1_start:theta1_end], (hidden_size1, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[theta1_end:theta2_end], (hidden_size2, (hidden_size1 + 1))))\n",
        "    theta3 = np.matrix(np.reshape(params[theta2_end:], (num_labels, (hidden_size2 + 1))))\n",
        "\n",
        "    # run the feed-forward pass\n",
        "    a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
        "\n",
        "    # compute the cost\n",
        "    J = 0\n",
        "    for i in range(m):\n",
        "        first_term = np.multiply(-y[i, :], np.log(h[i, :]))\n",
        "        second_term = np.multiply((1 - y[i, :]), np.log(1 - h[i, :]))\n",
        "        J += np.sum(first_term - second_term)\n",
        "\n",
        "    J = J / m\n",
        "\n",
        "    # add the cost regularization term\n",
        "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:, 1:], 2)) +\n",
        "                                             np.sum(np.power(theta2[:, 1:], 2)) +\n",
        "                                             np.sum(np.power(theta3[:, 1:], 2)))\n",
        "\n",
        "    return J\n",
        "\n"
      ],
      "metadata": {
        "id": "FGpDkL9--AIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_without_regularization(params, input_size, hidden_size1, hidden_size2, num_labels, X, y):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "\n",
        "    end_of_theta1 = hidden_size1 * (input_size + 1)\n",
        "    end_of_theta2 = end_of_theta1 + hidden_size2 * (hidden_size1 + 1)\n",
        "\n",
        "    theta1 = np.matrix(np.reshape(params[:end_of_theta1], (hidden_size1, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[end_of_theta1:end_of_theta2], (hidden_size2, (hidden_size1 + 1))))\n",
        "    theta3 = np.matrix(np.reshape(params[end_of_theta2:], (num_labels, (hidden_size2 + 1))))\n",
        "\n",
        "    # Run the forward propagation\n",
        "    a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
        "\n",
        "    # Compute the cost\n",
        "    J = 0\n",
        "    for i in range(m):\n",
        "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
        "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
        "        J += np.sum(first_term - second_term)\n",
        "\n",
        "    J = J / m\n",
        "\n",
        "    return J\n",
        "\n"
      ],
      "metadata": {
        "id": "1qvvtJX391wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initial setup\n",
        "input_size = 400\n",
        "hidden_size1 = 20  # Size of the first hidden layer\n",
        "hidden_size2 = 20  # Size of the second hidden layer\n",
        "num_labels = 10\n",
        "learning_rate = 1\n",
        "\n",
        "# randomly initialize a parameter array of the size of the full network's parameters\n",
        "params_size = (input_size + 1) * hidden_size1 + (hidden_size1 + 1) * hidden_size2 + (hidden_size2 + 1) * num_labels\n",
        "params = (np.random.random(size=params_size) - 0.5) * 0.25\n",
        "\n",
        "m = X.shape[0]\n",
        "X = np.matrix(X)\n",
        "y = np.matrix(y)\n",
        "\n",
        "# unravel the parameter array into parameter matrices for each layer\n",
        "end_hidden1 = hidden_size1 * (input_size + 1)\n",
        "end_hidden2 = end_hidden1 + hidden_size2 * (hidden_size1 + 1)\n",
        "theta1 = np.matrix(np.reshape(params[:end_hidden1], (hidden_size1, (input_size + 1))))\n",
        "theta2 = np.matrix(np.reshape(params[end_hidden1:end_hidden2], (hidden_size2, (hidden_size1 + 1))))\n",
        "theta3 = np.matrix(np.reshape(params[end_hidden2:], (num_labels, (hidden_size2 + 1))))\n",
        "\n",
        "print(theta1.shape, theta2.shape, theta3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g75uDo-dBFjD",
        "outputId": "5d3b5fa0-e17f-4dc8-c92b-fccbd0c3bb5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 401) (20, 21) (10, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
        "a1.shape, z2.shape, a2.shape, z3.shape, a3.shape, z4.shape, h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKrP4_kXBqfR",
        "outputId": "9c0589c1-55de-4deb-ca20-c582212b55a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 401),\n",
              " (5000, 20),\n",
              " (5000, 21),\n",
              " (5000, 20),\n",
              " (5000, 21),\n",
              " (5000, 10),\n",
              " (5000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_without_regularization(params, input_size, hidden_size1, hidden_size2, num_labels, X, y_onehot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dH0reh3Ct2S",
        "outputId": "bd065b7a-5123-43ec-e43f-fa3efa7551a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.767207292541944"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_with_regularization(params, input_size, hidden_size1, hidden_size2, num_labels, X, y_onehot, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKtZQuBVDK5L",
        "outputId": "fd0b1223-6599-439d-8629-6d9048665e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.771734275017079"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4"
      ],
      "metadata": {
        "id": "nrRm_0lM914k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_gradient(z):\n",
        "    return 2 * np.multiply(sigmoid(z), (1 - sigmoid(z)))"
      ],
      "metadata": {
        "id": "WGKHQ89q914l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5"
      ],
      "metadata": {
        "id": "UFAnt75y92BK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop_unregularized(params, input_size, hidden_size1, hidden_size2, num_labels, X, y):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "\n",
        "    end_of_theta1 = hidden_size1 * (input_size + 1)\n",
        "    end_of_theta2 = end_of_theta1 + hidden_size2 * (hidden_size1 + 1)\n",
        "\n",
        "    theta1 = np.matrix(np.reshape(params[:end_of_theta1], (hidden_size1, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[end_of_theta1:end_of_theta2], (hidden_size2, (hidden_size1 + 1))))\n",
        "    theta3 = np.matrix(np.reshape(params[end_of_theta2:], (num_labels, (hidden_size2 + 1))))\n",
        "\n",
        "    a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
        "\n",
        "    J = 0\n",
        "    delta1 = np.zeros(theta1.shape)\n",
        "    delta2 = np.zeros(theta2.shape)\n",
        "    delta3 = np.zeros(theta3.shape)\n",
        "\n",
        "    for i in range(m):\n",
        "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
        "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
        "        J += np.sum(first_term - second_term)\n",
        "\n",
        "    J = J / m\n",
        "\n",
        "    for t in range(m):\n",
        "        a1t = a1[t,:]\n",
        "        z2t = z2[t,:]\n",
        "        a2t = a2[t,:]\n",
        "        z3t = z3[t,:]\n",
        "        a3t = a3[t,:]\n",
        "        ht = h[t,:]\n",
        "        yt = y[t,:]\n",
        "\n",
        "        d4t = ht - yt\n",
        "        d3t = np.multiply((theta3.T * d4t.T).T, sigmoid_gradient(np.insert(z3t, 0, values=np.ones(1))))\n",
        "        d2t = np.multiply((theta2.T * d3t[:,1:].T).T, sigmoid_gradient(np.insert(z2t, 0, values=np.ones(1))))\n",
        "\n",
        "        delta1 += (d2t[:,1:]).T * a1t\n",
        "        delta2 += (d3t[:,1:]).T * a2t\n",
        "        delta3 += d4t.T * a3t\n",
        "\n",
        "    delta1 = delta1 / m\n",
        "    delta2 = delta2 / m\n",
        "    delta3 = delta3 / m\n",
        "\n",
        "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2), np.ravel(delta3)))\n",
        "\n",
        "    return J, grad"
      ],
      "metadata": {
        "id": "kNhNbo8Y-KLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop_regularized(params, input_size, hidden_size1, hidden_size2, num_labels, X, y, learning_rate):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "\n",
        "    end_of_theta1 = hidden_size1 * (input_size + 1)\n",
        "    end_of_theta2 = end_of_theta1 + hidden_size2 * (hidden_size1 + 1)\n",
        "\n",
        "    theta1 = np.matrix(np.reshape(params[:end_of_theta1], (hidden_size1, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[end_of_theta1:end_of_theta2], (hidden_size2, (hidden_size1 + 1))))\n",
        "    theta3 = np.matrix(np.reshape(params[end_of_theta2:], (num_labels, (hidden_size2 + 1))))\n",
        "\n",
        "    a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
        "\n",
        "    J = 0\n",
        "    delta1 = np.zeros(theta1.shape)\n",
        "    delta2 = np.zeros(theta2.shape)\n",
        "    delta3 = np.zeros(theta3.shape)\n",
        "\n",
        "    for i in range(m):\n",
        "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
        "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
        "        J += np.sum(first_term - second_term)\n",
        "\n",
        "    J = J / m\n",
        "\n",
        "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) +\n",
        "                                             np.sum(np.power(theta2[:,1:], 2)) +\n",
        "                                             np.sum(np.power(theta3[:,1:], 2)))\n",
        "\n",
        "    for t in range(m):\n",
        "        a1t = a1[t,:]\n",
        "        z2t = z2[t,:]\n",
        "        a2t = a2[t,:]\n",
        "        z3t = z3[t,:]\n",
        "        a3t = a3[t,:]\n",
        "        ht = h[t,:]\n",
        "        yt = y[t,:]\n",
        "\n",
        "        d4t = ht - yt\n",
        "        d3t = np.multiply((theta3.T * d4t.T).T, sigmoid_gradient(np.insert(z3t, 0, values=np.ones(1))))\n",
        "        d2t = np.multiply((theta2.T * d3t[:,1:].T).T, sigmoid_gradient(np.insert(z2t, 0, values=np.ones(1))))\n",
        "\n",
        "        delta1 += (d2t[:,1:]).T * a1t\n",
        "        delta2 += (d3t[:,1:]).T * a2t\n",
        "        delta3 += d4t.T * a3t\n",
        "\n",
        "    delta1 = delta1 / m\n",
        "    delta2 = delta2 / m\n",
        "    delta3 = delta3 / m\n",
        "\n",
        "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
        "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
        "    delta3[:,1:] = delta3[:,1:] + (theta3[:,1:] * learning_rate) / m\n",
        "\n",
        "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2), np.ravel(delta3)))\n",
        "\n",
        "    return J, grad\n"
      ],
      "metadata": {
        "id": "_LOlywen92BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "J, grad = backprop_unregularized(params, input_size, hidden_size1, hidden_size2, num_labels, X, y_onehot)\n",
        "J, grad.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMvJLZNBS8oB",
        "outputId": "72800d73-8ea3-43a9-e696-38b6d86840d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6.767207292541944, (8650,))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "J, grad = backprop_regularized(params, input_size, hidden_size1, hidden_size2, num_labels, X, y_onehot, learning_rate)\n",
        "J, grad.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kItjE-aSvv_",
        "outputId": "27af8ca0-f091-4bb6-f25b-6fd822cf40d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6.771734275017079, (8650,))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6"
      ],
      "metadata": {
        "id": "DpmTkUOL92Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "import pandas as pd\n",
        "\n",
        "#input feature\n",
        "input_size = 400\n",
        "#first hidden layer units\n",
        "hidden_size1 = 20\n",
        "#second hidden layer units\n",
        "hidden_size2 = 20\n",
        "# classes\n",
        "num_labels = 10\n",
        "learning_rate = 1\n",
        "\n",
        "# Randomly initialize weights\n",
        "params = (np.random.random(size=hidden_size1 * (input_size + 1) + hidden_size2 * (hidden_size1 + 1) + num_labels * (hidden_size2 + 1)) - 0.5) * 0.25\n",
        "\n",
        "# Minimize the objective function\n",
        "fmin = minimize(fun=backprop_unregularized, x0=params, args=(input_size, hidden_size1, hidden_size2, num_labels, X, y_onehot),\n",
        "                method='TNC', jac=True, options={'maxiter': 250})\n",
        "\n",
        "# Extract trained parameters\n",
        "X = np.matrix(X)\n",
        "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
        "theta2 = np.matrix(np.reshape(fmin.x[hidden_size1 * (input_size + 1):hidden_size1 * (input_size + 1) + hidden_size2 * (hidden_size1 + 1)], (hidden_size2, (hidden_size1 + 1))))\n",
        "theta3 = np.matrix(np.reshape(fmin.x[hidden_size1 * (input_size + 1) + hidden_size2 * (hidden_size1 + 1):], (num_labels, (hidden_size2 + 1))))"
      ],
      "metadata": {
        "id": "oKP1F-jP92Hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53bc558-ebfe-4886-ab6c-b912ee60a563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-d927eae6725c>:18: OptimizeWarning: Unknown solver options: maxiter\n",
            "  fmin = minimize(fun=backprop_unregularized, x0=params, args=(input_size, hidden_size1, hidden_size2, num_labels, X, y_onehot),\n",
            "<ipython-input-46-9e4380073be5>:22: RuntimeWarning: divide by zero encountered in log\n",
            "  second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
            "<ipython-input-46-9e4380073be5>:22: RuntimeWarning: invalid value encountered in multiply\n",
            "  second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7"
      ],
      "metadata": {
        "id": "gLPj7Jou92OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1, z2, a2, z3, a3, z4, h = forward_propagate(X, theta1, theta2, theta3)\n",
        "y_pred = np.array(np.argmax(h, axis=1) + 1)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "59v8hLZT92OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebeef52a-1fa6-4325-bd34-969699d8b8d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10],\n",
              "       [10],\n",
              "       [10],\n",
              "       ...,\n",
              "       [ 9],\n",
              "       [ 9],\n",
              "       [ 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_value = float(sum(a == b for a, b in zip(y_pred, y))) / len(y)\n",
        "print(f'accuracy = {accuracy_value * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51FQvyB7MRVP",
        "outputId": "813b1080-e81f-4b6c-c38f-04d2641102e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.8"
      ],
      "metadata": {
        "id": "QdXYjW4l92VA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**'\n",
        "The 3 layer NN I created achieved an 100.00% accuracy as compared to the example 2 layer NN which had a 99.22% accuracy. This indicates an improvement in capturing more features and patterns in the data with an additional layer of hidden network. However, the additiional layer did improve 100% accuracy may indicate there is overfitting as this is very high. Meaning it may not be worth it to increase the number of hidden layers.\n"
      ],
      "metadata": {
        "id": "45i7WFxc-Wyu"
      }
    }
  ]
}